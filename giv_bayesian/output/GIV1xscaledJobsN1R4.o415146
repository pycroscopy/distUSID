/lustre/or-hydra/cades-ccsd/syz/pycroscopy_ensemble/giv_bayesian_pure_mpi
total 321M
-rw-r--r-- 1 syz cades-ccsd  928 Sep 22 22:29 attribute_race_test.h5
-rw-r--r-- 1 syz cades-ccsd  721 Sep 25 16:28 bayesian_script_mpi.py
-rw-r--r-- 1 syz cades-ccsd  629 Sep 27 13:35 bayesian_script_single_node.py
-rw-r--r-- 1 syz cades-ccsd  19K Sep 27 13:35 giv_bayesian_mpi.py
-rw-r--r-- 1 syz cades-ccsd  15K Sep 21 18:23 giv_bayesian_mpi.pyc
-rwx------ 1 syz cades-ccsd 321M Sep 27 13:35 giv_raw.h5
-rw-r--r-- 1 syz cades-ccsd  21K Sep 27 13:35 giv_utils.py
-rw-r--r-- 1 syz cades-ccsd  619 Sep 22 22:28 h5_attribute_race_test.py
-rw-r--r-- 1 syz cades-ccsd  41K Sep 27 13:35 mpi_process.py
drwxr-sr-x 2 syz cades-ccsd  41K Sep 27 13:32 __pycache__
--------------------------------------------------------------------------
An MPI process has executed an operation involving a call to the
"fork()" system call to create a child process.  Open MPI is currently
operating in a condition that could result in memory corruption or
other system errors; your MPI job may hang, crash, or produce silent
data corruption.  The use of fork() (or system() or other calls that
create child processes) is strongly discouraged.  

The process that invoked fork was:

  Local host:          or-condo-c07 (PID 69761)
  MPI_COMM_WORLD rank: 0

If you are *absolutely sure* that your application will successfully
and correctly survive a call to fork(), you may disable this warning
by setting the mpi_warn_on_fork MCA parameter to 0.
--------------------------------------------------------------------------
No mpi4py found or script was not called via mpixexec / mpirun. Assuming single node computation
Rank 0 - on socket with 32 logical cores and 122.46 GB avail. RAM shared by 1 ranks each given 4 cores.
Allowed to read 16435752 pixels per chunk
Max positions per read set to 4000
Consider calling test() to check results before calling compute() which computes on the entire dataset and writes back to the HDF5 file
ensuring that half steps should be odd, num_x_steps is now 250
Checking for duplicates:
Creating HDF5 group and datasets to hold results
Now creating the datasets
created group: /Measurement_000/Channel_000/Raw_Data-FFT_Filtering_000/Filtered_Data-Reshape_000/Reshaped_Data-Bayesian_Inference_000 with attributes:
{'machine_id': 'or-condo-c07.ornl.gov', 'timestamp': '2018_09_27-13_35_13', 'pyUSID_version': '0.0.4', 'platform': 'Linux-3.10.0-327.4.4.el7.x86_64-x86_64-with-centos-7.5.1804-Core', 'tool': 'Bayesian_Inference', 'num_source_dsets': 1, 'source_000': <HDF5 object reference>, 'algorithm_author': 'Kody J. Law', 'last_pixel': 0, 'freq': 200.0, 'num_x_steps': 250, 'r_extra': 110, 'gam': 0.03, 'e': 10.0, 'sigma': 10.0, 'sigmaC': 1.0, 'num_samples': 2000.0}
Created I Corrected
Created Resistance
Created Variance
Created Capacitance
Done creating all results datasets!
Among the 68096 positions in this dataset, the following positions need to be computed: [    0     1     2 ... 68093 68094 68095].
Each rank is required to work on 68096 of the 68096 (remaining) positions in this dataset.
Rank 0 will read positions 0 to 68096 of 68096
	This class (likely) supports interruption and resuming of computations!
	If you are operating in a python console, press Ctrl+C or Cmd+C to abort
	If you are in a Jupyter notebook, click on "Kernel">>"Interrupt"
	If you are operating on a cluster and your job gets killed, re-run the job to resume

Rank: 0 - with nothing loaded has 122.46 GB free memory
Rank 0 - Read positions: [   0    1    2 ... 3997 3998 3999]
Rank: 0 - with only raw data loaded has 122.45 GB free memory
Rank 0 beginning parallel compute for Forward
Number of CPU free cores set to: 2 given that the CPU has 32 logical cores.
4 cores requested.
computational jobs per core = 1000. For short computations, each core must have at least 20 jobs to warrant parallel computation.
Computations are not lengthy.
Rank 0 starting computing on 4 cores (requested 4 cores)
--------------------------------------------------------------------------
An MPI process has executed an operation involving a call to the
"fork()" system call to create a child process.  Open MPI is currently
operating in a condition that could result in memory corruption or
other system errors; your MPI job may hang, crash, or produce silent
data corruption.  The use of fork() (or system() or other calls that
create child processes) is strongly discouraged.  

The process that invoked fork was:

  Local host:          or-condo-c07 (PID 69779)
  MPI_COMM_WORLD rank: 0

If you are *absolutely sure* that your application will successfully
and correctly survive a call to fork(), you may disable this warning
by setting the mpi_warn_on_fork MCA parameter to 0.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
An MPI process has executed an operation involving a call to the
"fork()" system call to create a child process.  Open MPI is currently
operating in a condition that could result in memory corruption or
other system errors; your MPI job may hang, crash, or produce silent
data corruption.  The use of fork() (or system() or other calls that
create child processes) is strongly discouraged.  

The process that invoked fork was:

  Local host:          or-condo-c07 (PID 69773)
  MPI_COMM_WORLD rank: 0

If you are *absolutely sure* that your application will successfully
and correctly survive a call to fork(), you may disable this warning
by setting the mpi_warn_on_fork MCA parameter to 0.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
An MPI process has executed an operation involving a call to the
"fork()" system call to create a child process.  Open MPI is currently
operating in a condition that could result in memory corruption or
other system errors; your MPI job may hang, crash, or produce silent
data corruption.  The use of fork() (or system() or other calls that
create child processes) is strongly discouraged.  

The process that invoked fork was:

  Local host:          or-condo-c07 (PID 69775)
  MPI_COMM_WORLD rank: 0

If you are *absolutely sure* that your application will successfully
and correctly survive a call to fork(), you may disable this warning
by setting the mpi_warn_on_fork MCA parameter to 0.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
An MPI process has executed an operation involving a call to the
"fork()" system call to create a child process.  Open MPI is currently
operating in a condition that could result in memory corruption or
other system errors; your MPI job may hang, crash, or produce silent
data corruption.  The use of fork() (or system() or other calls that
create child processes) is strongly discouraged.  

The process that invoked fork was:

  Local host:          or-condo-c07 (PID 69777)
  MPI_COMM_WORLD rank: 0

If you are *absolutely sure* that your application will successfully
and correctly survive a call to fork(), you may disable this warning
by setting the mpi_warn_on_fork MCA parameter to 0.
--------------------------------------------------------------------------
Rank 0 finished parallel computation
Rank 0 finished processing forward sections. Now working on reverse sections....
Number of CPU free cores set to: 2 given that the CPU has 32 logical cores.
4 cores requested.
computational jobs per core = 1000. For short computations, each core must have at least 20 jobs to warrant parallel computation.
Computations are not lengthy.
Rank 0 starting computing on 4 cores (requested 4 cores)
Rank 0 finished parallel computation
Rank 0 Finished processing reverse loops (and this chunk)
Rank 0 - computed chunk in 2.12 mins or 31.74 msec per pixel. Average: 31.74 msec per pixel.
Rank: 0 - now holding onto raw data + results has 122.02 GB free memory
Rank 0 - Started accumulating results for this chunk
Rank 0 - Finished accumulating results. Writing results of chunk to h5
Rank 0 - wrote its 4000 pixel chunk in 320.0 msec
Rank 0 - 5% complete. Time remaining: 33.99 mins
Rank 0 - Finished computing all jobs!
Finished processing the entire dataset!
Execution time: 127.84965324401855 sec
